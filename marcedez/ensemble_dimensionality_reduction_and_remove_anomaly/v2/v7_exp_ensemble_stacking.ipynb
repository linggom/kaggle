{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator,TransformerMixin, ClassifierMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.linear_model import ElasticNetCV, LassoLarsCV, LinearRegression, HuberRegressor, RANSACRegressor,BayesianRidge\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StackingEstimator(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, estimator):\n",
    "        self.estimator = estimator\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        self.estimator.fit(X, y, **fit_params)\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = check_array(X)\n",
    "        X_transformed = np.copy(X)\n",
    "        # add class probabilities as a synthetic feature\n",
    "        if issubclass(self.estimator.__class__, ClassifierMixin) and hasattr(self.estimator, 'predict_proba'):\n",
    "            X_transformed = np.hstack((self.estimator.predict_proba(X), X))\n",
    "\n",
    "        # add class prodiction as a synthetic feature\n",
    "        X_transformed = np.hstack((np.reshape(self.estimator.predict(X), (-1, 1)), X_transformed))\n",
    "\n",
    "        return X_transformed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probing = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "if probing:\n",
    "    train = pd.read_csv('../../data/train2.csv')    \n",
    "else:\n",
    "    train = pd.read_csv('../../data/train.csv')\n",
    "\n",
    "test = pd.read_csv('../../data/test.csv')\n",
    "original_train = pd.read_csv('../../data/train.csv')\n",
    "usable_columns = original_train.drop('y', axis=1).columns\n",
    "\n",
    "public_lb = pd.read_csv('../../data/public_lb.csv')\n",
    "public_lb['ID'] = public_lb.id\n",
    "public_lb['y'] = public_lb.yValue\n",
    "\n",
    "best = pd.read_csv('v7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# usable_columns = usable_columns[:3].append(usable_columns[10:])\n",
    "# usable_columns=['ID', 'X0', 'X47','X95','X314','X315','X232','X119','X311','X76','X329','X238','X340','X362','X137']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for c in train.columns:\n",
    "    if train[c].dtype == 'object':\n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(train[c].values) + list(test[c].values))\n",
    "        train[c] = lbl.transform(list(train[c].values))\n",
    "        test[c] = lbl.transform(list(test[c].values))\n",
    "\n",
    "\n",
    "\n",
    "n_comp = 12\n",
    "\n",
    "# tSVD\n",
    "tsvd = TruncatedSVD(n_components=n_comp, random_state=420)\n",
    "tsvd_results_train = tsvd.fit_transform(train.drop([\"y\"], axis=1))\n",
    "tsvd_results_test = tsvd.transform(test)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=n_comp, random_state=420)\n",
    "pca2_results_train = pca.fit_transform(train.drop([\"y\"], axis=1))\n",
    "pca2_results_test = pca.transform(test)\n",
    "\n",
    "# ICA\n",
    "ica = FastICA(n_components=n_comp, random_state=420)\n",
    "ica2_results_train = ica.fit_transform(train.drop([\"y\"], axis=1))\n",
    "ica2_results_test = ica.transform(test)\n",
    "\n",
    "# GRP\n",
    "grp = GaussianRandomProjection(n_components=n_comp, eps=0.1, random_state=420)\n",
    "grp_results_train = grp.fit_transform(train.drop([\"y\"], axis=1))\n",
    "grp_results_test = grp.transform(test)\n",
    "\n",
    "# SRP\n",
    "srp = SparseRandomProjection(n_components=n_comp, dense_output=True, random_state=420)\n",
    "srp_results_train = srp.fit_transform(train.drop([\"y\"], axis=1))\n",
    "srp_results_test = srp.transform(test)\n",
    "\n",
    "#save columns list before adding the decomposition components\n",
    "\n",
    "\n",
    "# Append decomposition components to datasets\n",
    "for i in range(1, n_comp + 1):\n",
    "    train['pca_' + str(i)] = pca2_results_train[:, i - 1]\n",
    "    test['pca_' + str(i)] = pca2_results_test[:, i - 1]\n",
    "\n",
    "    train['ica_' + str(i)] = ica2_results_train[:, i - 1]\n",
    "    test['ica_' + str(i)] = ica2_results_test[:, i - 1]\n",
    "\n",
    "    train['tsvd_' + str(i)] = tsvd_results_train[:, i - 1]\n",
    "    test['tsvd_' + str(i)] = tsvd_results_test[:, i - 1]\n",
    "\n",
    "    train['grp_' + str(i)] = grp_results_train[:, i - 1]\n",
    "    test['grp_' + str(i)] = grp_results_test[:, i - 1]\n",
    "\n",
    "    train['srp_' + str(i)] = srp_results_train[:, i - 1]\n",
    "    test['srp_' + str(i)] = srp_results_test[:, i - 1]\n",
    "\n",
    "y_train = train['y'].values\n",
    "y_mean = np.mean(y_train)\n",
    "id_test = test['ID'].values\n",
    "\n",
    "finaltrainset = train[usable_columns]\n",
    "finaltestset = test[usable_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stacked_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=LassoLarsCV(normalize=True)),\n",
    "    StackingEstimator(estimator=GradientBoostingRegressor(learning_rate=0.001, loss=\"huber\", max_depth=3, max_features=0.55, min_samples_leaf=18, min_samples_split=14, subsample=0.7)),\n",
    "    LassoLarsCV()\n",
    ")\n",
    "final = xgb.XGBRegressor(n_trees= 520,\n",
    "                eta=0.0045,\n",
    "                max_depth= 4,\n",
    "                subsample= 0.93,\n",
    "                objective= 'reg:linear',\n",
    "                eval_metric= 'rmse',\n",
    "                silent= 1)\n",
    "models =  [stacked_pipeline,\n",
    "            LinearRegression(),\n",
    "            RandomForestRegressor(),\n",
    "            LinearSVR(),\n",
    "           BayesianRidge(),\n",
    "           \n",
    "            DecisionTreeRegressor(max_depth=5),\n",
    "            final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ensemble(models, final_model, train_data, eval_data,  train_label, eval_label, xtest):\n",
    "    eval_preds = []\n",
    "    test_data = []\n",
    "    \n",
    "\n",
    "    \n",
    "    for model in models:\n",
    "        model.fit(train_data, train_label)\n",
    "        eval_preds.append(model.predict(eval_data))\n",
    "        test_data.append(model.predict(xtest))\n",
    "        \n",
    "    eval_predsT = np.array(eval_preds).T\n",
    "    final_model.fit(eval_predsT, eval_label)\n",
    "    score = r2_score(eval_label, final_model.predict(eval_predsT))\n",
    "    test_dataT = np.array(test_data).T\n",
    "    \n",
    "    return final_model.predict(test_dataT), score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++===============================++\n",
      "CV score :  0.747233184435\n",
      "++===============================++\n",
      "\n",
      "++===============================++\n",
      "CV score :  0.750936524305\n",
      "++===============================++\n",
      "\n",
      "++===============================++\n",
      "CV score :  0.756752412099\n",
      "++===============================++\n",
      "\n",
      "++===============================++\n",
      "CV score :  0.772014370668\n",
      "++===============================++\n",
      "\n",
      "++===============================++\n",
      "CV score :  0.739915975261\n",
      "++===============================++\n",
      "\n",
      "++===============================++\n",
      "CV score :  0.745664934475\n",
      "++===============================++\n",
      "\n",
      "++===============================++\n",
      "CV score :  0.734020028072\n",
      "++===============================++\n",
      "\n",
      "++===============================++\n",
      "CV score :  0.752396593449\n",
      "++===============================++\n",
      "\n",
      "++===============================++\n",
      "CV score :  0.745174126437\n",
      "++===============================++\n",
      "\n",
      "++===============================++\n",
      "CV score :  0.734819021751\n",
      "++===============================++\n",
      "\n",
      "r2 to probe :  0.747892717095\n",
      "rmse  to probe :  8.37853493803\n",
      "mae  to probe:  5.4212132482\n"
     ]
    }
   ],
   "source": [
    "r = []\n",
    "mae = []\n",
    "mse = []\n",
    "stack_preds = []\n",
    "from sklearn.svm import LinearSVR\n",
    "for i in range(10):\n",
    "    print(\"++===============================++\")\n",
    "    train_X, eval_X, train_y, eval_y = train_test_split(finaltrainset, y_train, test_size=0.2 )\n",
    "    cv_train_X, cv_eval_X, cv_train_y, cv_eval_y = train_test_split(train_X, train_y, test_size=0.6 )\n",
    "    stack_pred, score = ensemble(models, final, cv_train_X, cv_eval_X, cv_train_y, cv_eval_y, eval_X)\n",
    "    stack_preds.append(stack_pred)\n",
    "    print(\"CV score : \", score)\n",
    "    \n",
    "    r.append(score)\n",
    "    mse.append(np.sqrt(mean_squared_error(eval_y, stack_pred)))\n",
    "    mae.append(mean_absolute_error(eval_y, stack_pred))\n",
    "    print(\"++===============================++\\n\")\n",
    "\n",
    "print(\"r2 to probe : \", np.mean(r))\n",
    "print(\"rmse  to probe : \", np.mean(mse))\n",
    "print(\"mae  to probe: \", np.mean(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++===============================++\n",
      "CV score :  0.828567478066\n",
      "0 R2 score :  0.611725399897\n",
      "++===============================++\n",
      "\n",
      "++===============================++\n",
      "CV score :  0.841881297458\n",
      "1 R2 score :  0.655805929224\n",
      "++===============================++\n",
      "\n",
      "++===============================++\n",
      "CV score :  0.835074579992\n",
      "2 R2 score :  0.461904940157\n",
      "++===============================++\n",
      "\n",
      "++===============================++\n",
      "CV score :  0.854278639326\n",
      "3 R2 score :  0.0753208838145\n",
      "++===============================++\n",
      "\n",
      "++===============================++\n",
      "CV score :  0.797566575627\n",
      "4 R2 score :  0.723703151302\n",
      "++===============================++\n",
      "\n",
      "++===============================++\n"
     ]
    }
   ],
   "source": [
    "r = []\n",
    "mae = []\n",
    "mse = []\n",
    "stack_preds = []\n",
    "from sklearn.svm import LinearSVR\n",
    "for i in range(10):\n",
    "    print(\"++===============================++\")\n",
    "    train_X, eval_X, train_y, eval_y = train_test_split(finaltrainset, y_train, test_size=0.2 )\n",
    "    stack_pred, score = ensemble(models, final, train_X,eval_X, train_y, eval_y,finaltestset)\n",
    "    stack_preds.append(stack_pred)\n",
    "    print(\"CV score : \", score)\n",
    "    sub = pd.DataFrame()\n",
    "    sub['ID'] = id_test\n",
    "    sub['y'] = stack_pred#y_pred*0.75 + results*0.25\n",
    "    res = sub[sub.ID.isin(public_lb.id)]\n",
    "    print(i, \"R2 score : \", r2_score(public_lb.yValue, res.y))\n",
    "\n",
    "    r.append(r2_score(public_lb.yValue, res.y))\n",
    "    mse.append(np.sqrt(mean_squared_error(public_lb.yValue, res.y)))\n",
    "    mae.append(mean_absolute_error(public_lb.yValue, res.y))\n",
    "    print(\"++===============================++\\n\")\n",
    "\n",
    "print(\"r2 to probe : \", np.mean(r))\n",
    "print(\"rmse  to probe : \", np.mean(mse))\n",
    "print(\"mae  to probe: \", np.mean(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack_predsT = np.array(stack_preds).T\n",
    "stack_predsTM = np.mean(stack_predsT,axis=1)\n",
    "stack_predsTM.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y_pred = model.predict(dtest)\n",
    "# results = stacked_pipeline.predict(finaltestset)\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub['ID'] = id_test\n",
    "sub['y'] = stack_predsTM#y_pred*0.75 + results*0.25\n",
    "res = sub[sub.ID.isin(public_lb.id)]\n",
    "result = r2_score(public_lb.yValue, res.y)\n",
    "print(\"r2 to probe : \", r2_score(public_lb.yValue, res.y))\n",
    "print(\"mse  to probe : \", mean_squared_error(public_lb.yValue, res.y))\n",
    "print(\"mae  to probe: \", mean_absolute_error(public_lb.yValue, res.y))\n",
    "exception = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base Results = 0.720429268928"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if probing:\n",
    "    first = sub[sub.ID.isin(public_lb.id) == False]\n",
    "    second = public_lb[['ID', 'y']]\n",
    "    sub2 = first.append(second, ignore_index=True)\n",
    "    sub2 = sub2.sort_values('ID', ascending=True)\n",
    "else:\n",
    "    sub2 = sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(r2_score(best.y, sub2.y ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sanity check\n",
    "r2_score(public_lb.yValue, sub2[sub2.ID.isin(public_lb.id)].y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sanity_check= sub2[pd.isnull(sub2.y)].shape[0]\n",
    "print(sub2.shape)\n",
    "print(sanity_check == 0)\n",
    "print(sub2.shape[0] == test.shape[0])\n",
    "if sanity_check == 0 and sub2.shape[0] == test.shape[0] and (result + 0.001 > 0.720429268928 or exception):\n",
    "    sub2.to_csv('stacked-models7.csv', index=False)\n",
    "    print(\"saved\")\n",
    "else:\n",
    "    print(\"below can't continue\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
