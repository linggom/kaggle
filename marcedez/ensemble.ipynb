{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Righnow candidate is : SVR with PCA n_components = 10 with results 0.23706564506631833"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LinearRegression, TheilSenRegressor,RANSACRegressor,HuberRegressor\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>az</td>\n",
       "      <td>v</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>w</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>t</td>\n",
       "      <td>b</td>\n",
       "      <td>ai</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>b</td>\n",
       "      <td>g</td>\n",
       "      <td>y</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>az</td>\n",
       "      <td>v</td>\n",
       "      <td>as</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "      <td>j</td>\n",
       "      <td>j</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>az</td>\n",
       "      <td>l</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>z</td>\n",
       "      <td>l</td>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>w</td>\n",
       "      <td>s</td>\n",
       "      <td>as</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>y</td>\n",
       "      <td>i</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 377 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  X0 X1  X2 X3 X4 X5 X6 X8  X10  ...   X375  X376  X377  X378  X379  \\\n",
       "0   1  az  v   n  f  d  t  a  w    0  ...      0     0     0     1     0   \n",
       "1   2   t  b  ai  a  d  b  g  y    0  ...      0     0     1     0     0   \n",
       "2   3  az  v  as  f  d  a  j  j    0  ...      0     0     0     1     0   \n",
       "3   4  az  l   n  f  d  z  l  n    0  ...      0     0     0     1     0   \n",
       "4   5   w  s  as  c  d  y  i  m    0  ...      1     0     0     0     0   \n",
       "\n",
       "   X380  X382  X383  X384  X385  \n",
       "0     0     0     0     0     0  \n",
       "1     0     0     0     0     0  \n",
       "2     0     0     0     0     0  \n",
       "3     0     0     0     0     0  \n",
       "4     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 377 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = train.iloc[:,1]\n",
    "train_feats = train.iloc[:, 2:]\n",
    "\n",
    "test_labels = test.iloc[:,1]\n",
    "test_feats = test.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_feats_encode = []\n",
    "train_feats_encode.append(train.iloc[:, 0])\n",
    "for i in range(train_feats.shape[1]):\n",
    "    arr = train_feats.iloc[:, i]\n",
    "    if arr.dtype == 'O':        \n",
    "        lblencod = LabelEncoder()\n",
    "        arr = lblencod.fit_transform(arr)\n",
    "    train_feats_encode.append(arr)\n",
    "train_feats_encode = np.array(train_feats_encode).T\n",
    "\n",
    "test_feats_encode = []\n",
    "test_feats_encode.append(test.iloc[:, 0])\n",
    "for i in range(test_feats.shape[1]):\n",
    "    arr = test_feats.iloc[:, i]\n",
    "    if arr.dtype == 'O':        \n",
    "        lblencod = LabelEncoder()\n",
    "        arr = lblencod.fit_transform(arr)\n",
    "    test_feats_encode.append(arr)\n",
    "test_feats_encode = np.array(test_feats_encode).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellen=['ID', 'X47','X95','X314','X315','X232','X119','X311','X76','X329','X238','X340','X362','X137']\n",
    "train_feats_encode = train[cellen].as_matrix()\n",
    "test_feats_encode = test[cellen].as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start to do the ensemble method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***XGBOOST***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***SVR***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Linear Regression***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** SGD Regressor ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Keras Deep Learning ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# define custom R2 metrics for Keras backend\n",
    "from keras import backend as K\n",
    "# to tune the NN\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD, Adam\n",
    "act_func = 'tanh'\n",
    "input_dims = train_feats_encode.shape[1]\n",
    "\n",
    "def r2_keras(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square( y_true - y_pred )) \n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) ) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# base model architecture definition\n",
    "def model():\n",
    "    model = Sequential()\n",
    "    #input layer\n",
    "    model.add(Dense(input_dims, input_dim=input_dims))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    # hidden layers\n",
    "    model.add(Dense(input_dims))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act_func))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(input_dims//2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(act_func))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(input_dims//4, activation=act_func))\n",
    "    \n",
    "    # output layer (y_pred)\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    # compile this model\n",
    "    model.compile(loss='mean_squared_error', # one may use 'mean_absolute_error' as alternative\n",
    "                  optimizer='adam',\n",
    "                  metrics=[r2_keras] # you can add several if needed\n",
    "                 )\n",
    "    \n",
    "    # Visualize NN architecture\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KerasRegressor(\n",
    "    build_fn=model, \n",
    "    nb_epoch=100, \n",
    "    batch_size=20,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Gradient Boosting Regressor **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X, eval_X, train_y, eval_y = train_test_split(train_feats_encode, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check(model):\n",
    "    pred_train = model.predict(train_X)\n",
    "    score_train = r2_score(train_y, pred_train)\n",
    "    pred_eval = model.predict(eval_X)\n",
    "    score_eval = r2_score(eval_y, pred_eval)\n",
    "    print(model.__class__.__name__)\n",
    "    print(\"r2 train = \", score_train)\n",
    "    print(\"r2 eval = \", score_eval)\n",
    "    print(\"====================================================\\n\")\n",
    "    return score_train, score_eval, pred_train, pred_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_model():\n",
    "    \n",
    "    model_theilsen = TheilSenRegressor(random_state=42)\n",
    "    model_theilsen.fit(train_X, train_y)\n",
    "    train_theilsen, test_theilsen, pred_train_theilsen, pred_eval_theilsen = check(model_theilsen)\n",
    "\n",
    "    model_ransac = RANSACRegressor(random_state=42)\n",
    "    model_ransac.fit(train_X, train_y)\n",
    "    train_ransac, test_ransac, pred_train_ransac, pred_eval_ransac = check(model_ransac)\n",
    "\n",
    "    model_huber = HuberRegressor()\n",
    "    model_huber.fit(train_X, train_y)\n",
    "    train_huber, test_huber, pred_train_huber, pred_eval_huber = check(model_huber)\n",
    "\n",
    "    \n",
    "    model_linear = LinearRegression()\n",
    "    model_linear.fit(train_X, train_y)\n",
    "    train_lr, test_lr, pred_train_lr, pred_eval_lr = check(model_linear)\n",
    "\n",
    "    model_sgd = SGDRegressor()\n",
    "    model_sgd.fit(train_X, train_y)\n",
    "    train_sgd, test_sgd, pred_train_sgd, pred_eval_sgd = check(model_sgd)\n",
    "        \n",
    "    model_xgb = XGBRegressor(seed = 0,\n",
    "      colsample_bytree = 0.7,\n",
    "      subsample = 0.9,\n",
    "      eta = 0.005,\n",
    "      max_depth = 4,\n",
    "      num_parallel_tree = 1,\n",
    "      min_child_weight = 1, objective='reg:linear', base_score=np.mean(train_labels))\n",
    "    model_xgb.fit(train_X, train_y)\n",
    "    train_xgb, test_xgb, pred_train_xgb, pred_eval_xgb = check(model_xgb)\n",
    "    \n",
    "    model_gbr = GradientBoostingRegressor()\n",
    "    model_gbr.fit(train_X, train_y)\n",
    "    train_gbr, test_gbr, pred_train_gbr, pred_eval_gbr = check(model_gbr)\n",
    "    \n",
    "    estimator.fit(\n",
    "        train_feats_encode, \n",
    "        train_labels, \n",
    "        epochs=300, # increase it to 20-100 to get better results\n",
    "        verbose=2,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    train_dl, test_dl, pred_train_dl, pred_eval_dl = check(estimator)\n",
    "    \n",
    "    columns=['lr', 'sgd', 'xgb', 'gbr', 'dl', 'thelisen', 'ransac', 'huber']\n",
    "   \n",
    "    test_res = (pred_eval_lr, pred_eval_sgd, pred_eval_xgb, pred_eval_gbr, pred_eval_dl, pred_eval_theilsen, pred_eval_ransac, pred_eval_huber)\n",
    "    \n",
    "    train_res = (pred_train_lr, pred_train_sgd, pred_train_xgb, pred_train_gbr, pred_train_dl, pred_train_theilsen, pred_train_ransac, pred_train_huber)\n",
    "    \n",
    "    train_res_pd = pd.DataFrame(data=np.column_stack(train_res),\n",
    "                  columns=columns)\n",
    "    \n",
    "    test_res_pd = pd.DataFrame(data=np.column_stack(test_res),\n",
    "                  columns=columns)\n",
    "    models = [model_linear, model_sgd, model_xgb, model_gbr, estimator, model_theilsen, model_ransac, model_huber]\n",
    "    return train_res_pd, test_res_pd, models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheilSenRegressor\n",
      "r2 train =  0.159201332928\n",
      "r2 eval =  0.293265801864\n",
      "====================================================\n",
      "\n",
      "RANSACRegressor\n",
      "r2 train =  0.427183244977\n",
      "r2 eval =  0.449259284886\n",
      "====================================================\n",
      "\n",
      "HuberRegressor\n",
      "r2 train =  0.158524138962\n",
      "r2 eval =  0.298549780541\n",
      "====================================================\n",
      "\n",
      "LinearRegression\n",
      "r2 train =  0.546072065004\n",
      "r2 eval =  0.591935097314\n",
      "====================================================\n",
      "\n",
      "SGDRegressor\n",
      "r2 train =  -3.71882219809e+30\n",
      "r2 eval =  -3.70582255637e+30\n",
      "====================================================\n",
      "\n",
      "XGBRegressor\n",
      "r2 train =  0.656287917263\n",
      "r2 eval =  0.599995096358\n",
      "====================================================\n",
      "\n",
      "GradientBoostingRegressor\n",
      "r2 train =  0.621485051292\n",
      "r2 eval =  0.604012222866\n",
      "====================================================\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 14)                210       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 14)                56        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 14)                210       \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 14)                56        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 7)                 105       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 7)                 28        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 7)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 7)                 0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 24        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 693\n",
      "Trainable params: 623\n",
      "Non-trainable params: 70\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/300\n",
      "2s - loss: 10160.9104 - r2_keras: -7.8154e+01\n",
      "Epoch 2/300\n",
      "0s - loss: 9748.8688 - r2_keras: -7.5107e+01\n",
      "Epoch 3/300\n",
      "0s - loss: 9280.7962 - r2_keras: -7.1716e+01\n",
      "Epoch 4/300\n",
      "0s - loss: 9020.8094 - r2_keras: -6.9643e+01\n",
      "Epoch 5/300\n",
      "0s - loss: 8824.0165 - r2_keras: -6.8934e+01\n",
      "Epoch 6/300\n",
      "0s - loss: 8647.8893 - r2_keras: -6.5747e+01\n",
      "Epoch 7/300\n",
      "0s - loss: 8481.2166 - r2_keras: -6.5096e+01\n",
      "Epoch 8/300\n",
      "0s - loss: 8320.5401 - r2_keras: -6.4063e+01\n",
      "Epoch 9/300\n",
      "0s - loss: 8164.8496 - r2_keras: -6.2747e+01\n",
      "Epoch 10/300\n",
      "0s - loss: 8012.8346 - r2_keras: -6.0591e+01\n",
      "Epoch 11/300\n",
      "0s - loss: 7863.8328 - r2_keras: -5.9784e+01\n",
      "Epoch 12/300\n",
      "0s - loss: 7718.2136 - r2_keras: -5.8873e+01\n",
      "Epoch 13/300\n",
      "0s - loss: 7573.8731 - r2_keras: -5.9802e+01\n",
      "Epoch 14/300\n",
      "0s - loss: 7431.9366 - r2_keras: -5.7969e+01\n",
      "Epoch 15/300\n",
      "0s - loss: 7292.1571 - r2_keras: -5.5240e+01\n",
      "Epoch 16/300\n",
      "0s - loss: 7154.5045 - r2_keras: -5.4534e+01\n",
      "Epoch 17/300\n",
      "0s - loss: 7018.8381 - r2_keras: -5.3818e+01\n",
      "Epoch 18/300\n",
      "0s - loss: 6883.9071 - r2_keras: -5.1141e+01\n",
      "Epoch 19/300\n",
      "0s - loss: 6751.5156 - r2_keras: -5.2126e+01\n",
      "Epoch 20/300\n",
      "0s - loss: 6620.1186 - r2_keras: -4.9950e+01\n",
      "Epoch 21/300\n",
      "0s - loss: 6490.6976 - r2_keras: -4.9034e+01\n",
      "Epoch 22/300\n",
      "0s - loss: 6362.8660 - r2_keras: -4.8173e+01\n",
      "Epoch 23/300\n",
      "0s - loss: 6235.6939 - r2_keras: -4.8163e+01\n",
      "Epoch 24/300\n",
      "0s - loss: 6110.8986 - r2_keras: -4.8109e+01\n",
      "Epoch 25/300\n",
      "0s - loss: 5986.8740 - r2_keras: -4.6316e+01\n",
      "Epoch 26/300\n",
      "0s - loss: 5864.9493 - r2_keras: -4.4512e+01\n",
      "Epoch 27/300\n",
      "0s - loss: 5744.0296 - r2_keras: -4.3768e+01\n",
      "Epoch 28/300\n",
      "0s - loss: 5624.4333 - r2_keras: -4.3226e+01\n",
      "Epoch 29/300\n",
      "0s - loss: 5506.5738 - r2_keras: -4.1875e+01\n",
      "Epoch 30/300\n",
      "0s - loss: 5389.5762 - r2_keras: -3.9874e+01\n",
      "Epoch 31/300\n",
      "0s - loss: 5274.3396 - r2_keras: -4.1336e+01\n",
      "Epoch 32/300\n",
      "0s - loss: 5160.6856 - r2_keras: -3.9703e+01\n",
      "Epoch 33/300\n",
      "0s - loss: 5047.8539 - r2_keras: -3.8236e+01\n",
      "Epoch 34/300\n",
      "0s - loss: 4936.7042 - r2_keras: -3.7326e+01\n",
      "Epoch 35/300\n",
      "0s - loss: 4827.2628 - r2_keras: -3.6603e+01\n",
      "Epoch 36/300\n",
      "0s - loss: 4719.0818 - r2_keras: -3.7177e+01\n",
      "Epoch 37/300\n",
      "0s - loss: 4611.8408 - r2_keras: -3.4641e+01\n",
      "Epoch 38/300\n",
      "0s - loss: 4505.7430 - r2_keras: -3.3355e+01\n",
      "Epoch 39/300\n",
      "0s - loss: 4401.4033 - r2_keras: -3.2925e+01\n",
      "Epoch 40/300\n",
      "0s - loss: 4298.5438 - r2_keras: -3.2176e+01\n",
      "Epoch 41/300\n",
      "0s - loss: 4196.6577 - r2_keras: -3.2128e+01\n",
      "Epoch 42/300\n",
      "0s - loss: 4096.0608 - r2_keras: -3.1113e+01\n",
      "Epoch 43/300\n",
      "0s - loss: 3997.1989 - r2_keras: -3.0071e+01\n",
      "Epoch 44/300\n",
      "0s - loss: 3899.4983 - r2_keras: -2.9599e+01\n",
      "Epoch 45/300\n",
      "0s - loss: 3802.9932 - r2_keras: -2.8807e+01\n",
      "Epoch 46/300\n",
      "0s - loss: 3707.9030 - r2_keras: -2.7538e+01\n",
      "Epoch 47/300\n",
      "0s - loss: 3614.3127 - r2_keras: -2.7224e+01\n",
      "Epoch 48/300\n",
      "0s - loss: 3521.9874 - r2_keras: -2.6647e+01\n",
      "Epoch 49/300\n",
      "0s - loss: 3430.9230 - r2_keras: -2.5714e+01\n",
      "Epoch 50/300\n",
      "0s - loss: 3341.3130 - r2_keras: -2.4769e+01\n",
      "Epoch 51/300\n",
      "0s - loss: 3252.7823 - r2_keras: -2.4431e+01\n",
      "Epoch 52/300\n",
      "0s - loss: 3165.6629 - r2_keras: -2.3519e+01\n",
      "Epoch 53/300\n",
      "0s - loss: 3080.0815 - r2_keras: -2.3221e+01\n",
      "Epoch 54/300\n",
      "0s - loss: 2995.6533 - r2_keras: -2.2320e+01\n",
      "Epoch 55/300\n",
      "0s - loss: 2912.5619 - r2_keras: -2.1837e+01\n",
      "Epoch 56/300\n",
      "0s - loss: 2830.7930 - r2_keras: -2.1086e+01\n",
      "Epoch 57/300\n",
      "0s - loss: 2750.2444 - r2_keras: -2.0042e+01\n",
      "Epoch 58/300\n",
      "0s - loss: 2671.3872 - r2_keras: -1.9363e+01\n",
      "Epoch 59/300\n",
      "0s - loss: 2593.3497 - r2_keras: -1.8967e+01\n",
      "Epoch 60/300\n",
      "0s - loss: 2516.8519 - r2_keras: -1.8279e+01\n",
      "Epoch 61/300\n",
      "0s - loss: 2441.6486 - r2_keras: -1.7558e+01\n",
      "Epoch 62/300\n",
      "0s - loss: 2367.6601 - r2_keras: -1.7295e+01\n",
      "Epoch 63/300\n",
      "0s - loss: 2295.0635 - r2_keras: -1.7084e+01\n",
      "Epoch 64/300\n",
      "0s - loss: 2223.8044 - r2_keras: -1.6017e+01\n",
      "Epoch 65/300\n",
      "0s - loss: 2153.9482 - r2_keras: -1.5682e+01\n",
      "Epoch 66/300\n",
      "0s - loss: 2085.3956 - r2_keras: -1.5054e+01\n",
      "Epoch 67/300\n",
      "0s - loss: 2017.9440 - r2_keras: -1.4548e+01\n",
      "Epoch 68/300\n",
      "0s - loss: 1951.8540 - r2_keras: -1.3814e+01\n",
      "Epoch 69/300\n",
      "0s - loss: 1886.9556 - r2_keras: -1.3497e+01\n",
      "Epoch 70/300\n",
      "0s - loss: 1823.4637 - r2_keras: -1.2889e+01\n",
      "Epoch 71/300\n",
      "0s - loss: 1761.3012 - r2_keras: -1.2330e+01\n",
      "Epoch 72/300\n",
      "0s - loss: 1700.3319 - r2_keras: -1.1814e+01\n",
      "Epoch 73/300\n",
      "0s - loss: 1640.7130 - r2_keras: -1.1624e+01\n",
      "Epoch 74/300\n",
      "0s - loss: 1582.2749 - r2_keras: -1.1175e+01\n",
      "Epoch 75/300\n",
      "0s - loss: 1525.2076 - r2_keras: -1.0735e+01\n",
      "Epoch 76/300\n",
      "0s - loss: 1469.4292 - r2_keras: -1.0284e+01\n",
      "Epoch 77/300\n",
      "0s - loss: 1414.9718 - r2_keras: -9.7632e+00\n",
      "Epoch 78/300\n",
      "0s - loss: 1361.9215 - r2_keras: -9.5459e+00\n",
      "Epoch 79/300\n",
      "0s - loss: 1309.6326 - r2_keras: -8.9658e+00\n",
      "Epoch 80/300\n",
      "0s - loss: 1258.9060 - r2_keras: -8.5634e+00\n",
      "Epoch 81/300\n",
      "0s - loss: 1209.3903 - r2_keras: -8.0955e+00\n",
      "Epoch 82/300\n",
      "0s - loss: 1161.2310 - r2_keras: -7.8794e+00\n",
      "Epoch 83/300\n",
      "0s - loss: 1114.2929 - r2_keras: -7.4572e+00\n",
      "Epoch 84/300\n",
      "0s - loss: 1068.7136 - r2_keras: -6.9241e+00\n",
      "Epoch 85/300\n",
      "0s - loss: 1024.1615 - r2_keras: -6.6583e+00\n",
      "Epoch 86/300\n",
      "0s - loss: 980.9278 - r2_keras: -6.3512e+00\n",
      "Epoch 87/300\n",
      "0s - loss: 939.0462 - r2_keras: -6.1285e+00\n",
      "Epoch 88/300\n",
      "0s - loss: 898.2183 - r2_keras: -5.7120e+00\n",
      "Epoch 89/300\n",
      "0s - loss: 858.7414 - r2_keras: -5.3944e+00\n",
      "Epoch 90/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s - loss: 820.3853 - r2_keras: -5.1381e+00\n",
      "Epoch 91/300\n",
      "0s - loss: 783.2649 - r2_keras: -4.9187e+00\n",
      "Epoch 92/300\n",
      "0s - loss: 747.4603 - r2_keras: -4.5930e+00\n",
      "Epoch 93/300\n",
      "0s - loss: 712.7452 - r2_keras: -4.2706e+00\n",
      "Epoch 94/300\n",
      "0s - loss: 679.1980 - r2_keras: -4.0276e+00\n",
      "Epoch 95/300\n",
      "0s - loss: 646.9456 - r2_keras: -3.7933e+00\n",
      "Epoch 96/300\n",
      "0s - loss: 615.8077 - r2_keras: -3.5029e+00\n",
      "Epoch 97/300\n",
      "0s - loss: 585.8889 - r2_keras: -3.3047e+00\n",
      "Epoch 98/300\n",
      "0s - loss: 557.1025 - r2_keras: -3.0205e+00\n",
      "Epoch 99/300\n",
      "0s - loss: 529.4222 - r2_keras: -2.8276e+00\n",
      "Epoch 100/300\n",
      "0s - loss: 502.9619 - r2_keras: -2.7052e+00\n",
      "Epoch 101/300\n",
      "0s - loss: 477.6463 - r2_keras: -2.4282e+00\n",
      "Epoch 102/300\n",
      "0s - loss: 453.4839 - r2_keras: -2.2844e+00\n",
      "Epoch 103/300\n",
      "0s - loss: 430.4078 - r2_keras: -2.1015e+00\n",
      "Epoch 104/300\n",
      "0s - loss: 408.4279 - r2_keras: -1.9568e+00\n",
      "Epoch 105/300\n",
      "0s - loss: 387.5805 - r2_keras: -1.7519e+00\n",
      "Epoch 106/300\n",
      "0s - loss: 367.8289 - r2_keras: -1.6269e+00\n",
      "Epoch 107/300\n",
      "0s - loss: 349.0979 - r2_keras: -1.4405e+00\n",
      "Epoch 108/300\n",
      "0s - loss: 331.4757 - r2_keras: -1.3202e+00\n",
      "Epoch 109/300\n",
      "0s - loss: 314.8603 - r2_keras: -1.1815e+00\n",
      "Epoch 110/300\n",
      "0s - loss: 299.2908 - r2_keras: -1.0872e+00\n",
      "Epoch 111/300\n",
      "0s - loss: 284.6924 - r2_keras: -9.7291e-01\n",
      "Epoch 112/300\n",
      "0s - loss: 271.1274 - r2_keras: -8.7271e-01\n",
      "Epoch 113/300\n",
      "0s - loss: 258.5273 - r2_keras: -7.6969e-01\n",
      "Epoch 114/300\n",
      "0s - loss: 246.8812 - r2_keras: -6.6909e-01\n",
      "Epoch 115/300\n",
      "0s - loss: 236.1256 - r2_keras: -5.9685e-01\n",
      "Epoch 116/300\n",
      "0s - loss: 226.3189 - r2_keras: -5.2053e-01\n",
      "Epoch 117/300\n",
      "0s - loss: 217.3406 - r2_keras: -4.6392e-01\n",
      "Epoch 118/300\n",
      "0s - loss: 209.2283 - r2_keras: -4.0006e-01\n",
      "Epoch 119/300\n",
      "0s - loss: 201.9379 - r2_keras: -3.4934e-01\n",
      "Epoch 120/300\n",
      "0s - loss: 195.4454 - r2_keras: -3.0515e-01\n",
      "Epoch 121/300\n",
      "0s - loss: 189.6569 - r2_keras: -2.4148e-01\n",
      "Epoch 122/300\n",
      "0s - loss: 184.5868 - r2_keras: -2.2178e-01\n",
      "Epoch 123/300\n",
      "0s - loss: 180.1665 - r2_keras: -1.9242e-01\n",
      "Epoch 124/300\n",
      "0s - loss: 176.3676 - r2_keras: -1.5896e-01\n",
      "Epoch 125/300\n",
      "0s - loss: 173.1296 - r2_keras: -1.3651e-01\n",
      "Epoch 126/300\n",
      "0s - loss: 170.4190 - r2_keras: -1.1514e-01\n",
      "Epoch 127/300\n",
      "0s - loss: 168.2077 - r2_keras: -9.9005e-02\n",
      "Epoch 128/300\n",
      "0s - loss: 166.3877 - r2_keras: -8.3876e-02\n",
      "Epoch 129/300\n",
      "0s - loss: 164.9147 - r2_keras: -7.9110e-02\n",
      "Epoch 130/300\n",
      "0s - loss: 163.7703 - r2_keras: -6.7745e-02\n",
      "Epoch 131/300\n",
      "0s - loss: 162.8999 - r2_keras: -6.9291e-02\n",
      "Epoch 132/300\n",
      "0s - loss: 162.2468 - r2_keras: -7.0506e-02\n",
      "Epoch 133/300\n",
      "0s - loss: 161.7661 - r2_keras: -5.6356e-02\n",
      "Epoch 134/300\n",
      "0s - loss: 161.4241 - r2_keras: -6.0721e-02\n",
      "Epoch 135/300\n",
      "0s - loss: 161.1914 - r2_keras: -6.2516e-02\n",
      "Epoch 136/300\n",
      "0s - loss: 161.0257 - r2_keras: -6.2455e-02\n",
      "Epoch 137/300\n",
      "0s - loss: 160.9161 - r2_keras: -5.7202e-02\n",
      "Epoch 138/300\n",
      "0s - loss: 160.8512 - r2_keras: -5.9995e-02\n",
      "Epoch 139/300\n",
      "0s - loss: 160.8049 - r2_keras: -5.1055e-02\n",
      "Epoch 140/300\n",
      "0s - loss: 160.7747 - r2_keras: -7.0753e-02\n",
      "Epoch 141/300\n",
      "0s - loss: 160.7596 - r2_keras: -6.3674e-02\n",
      "Epoch 142/300\n",
      "0s - loss: 160.7687 - r2_keras: -5.4578e-02\n",
      "Epoch 143/300\n",
      "0s - loss: 160.7400 - r2_keras: -6.1411e-02\n",
      "Epoch 144/300\n",
      "0s - loss: 160.7399 - r2_keras: -6.3115e-02\n",
      "Epoch 145/300\n",
      "0s - loss: 160.7371 - r2_keras: -6.2810e-02\n",
      "Epoch 146/300\n",
      "0s - loss: 160.7418 - r2_keras: -6.0926e-02\n",
      "Epoch 147/300\n",
      "0s - loss: 160.7355 - r2_keras: -5.9587e-02\n",
      "Epoch 148/300\n",
      "0s - loss: 160.7334 - r2_keras: -6.8009e-02\n",
      "Epoch 149/300\n",
      "0s - loss: 160.7473 - r2_keras: -5.9525e-02\n",
      "Epoch 150/300\n",
      "0s - loss: 160.7380 - r2_keras: -6.6922e-02\n",
      "Epoch 151/300\n",
      "0s - loss: 160.7375 - r2_keras: -6.0639e-02\n",
      "Epoch 152/300\n",
      "0s - loss: 160.7497 - r2_keras: -5.7365e-02\n",
      "Epoch 153/300\n",
      "0s - loss: 160.7457 - r2_keras: -5.4663e-02\n",
      "Epoch 154/300\n",
      "0s - loss: 160.7554 - r2_keras: -7.1701e-02\n",
      "Epoch 155/300\n",
      "0s - loss: 160.7386 - r2_keras: -5.4792e-02\n",
      "Epoch 156/300\n",
      "0s - loss: 160.7411 - r2_keras: -5.7028e-02\n",
      "Epoch 157/300\n",
      "0s - loss: 160.7269 - r2_keras: -6.0487e-02\n",
      "Epoch 158/300\n",
      "0s - loss: 160.7536 - r2_keras: -5.2161e-02\n",
      "Epoch 159/300\n",
      "0s - loss: 160.7482 - r2_keras: -6.1078e-02\n",
      "Epoch 160/300\n",
      "0s - loss: 160.7414 - r2_keras: -8.2527e-02\n",
      "Epoch 161/300\n",
      "0s - loss: 160.7416 - r2_keras: -6.6549e-02\n",
      "Epoch 162/300\n",
      "0s - loss: 160.7414 - r2_keras: -7.0918e-02\n",
      "Epoch 163/300\n",
      "0s - loss: 160.7404 - r2_keras: -5.5432e-02\n",
      "Epoch 164/300\n",
      "0s - loss: 160.7301 - r2_keras: -6.5042e-02\n",
      "Epoch 165/300\n",
      "0s - loss: 160.7289 - r2_keras: -5.1382e-02\n",
      "Epoch 166/300\n",
      "0s - loss: 160.7335 - r2_keras: -5.1144e-02\n",
      "Epoch 167/300\n",
      "0s - loss: 160.7366 - r2_keras: -5.6903e-02\n",
      "Epoch 168/300\n",
      "0s - loss: 160.7373 - r2_keras: -6.4160e-02\n",
      "Epoch 169/300\n",
      "0s - loss: 160.7356 - r2_keras: -7.3209e-02\n",
      "Epoch 170/300\n",
      "0s - loss: 160.7362 - r2_keras: -6.1786e-02\n",
      "Epoch 171/300\n",
      "0s - loss: 160.7460 - r2_keras: -7.4841e-02\n",
      "Epoch 172/300\n",
      "0s - loss: 160.7384 - r2_keras: -6.5069e-02\n",
      "Epoch 173/300\n",
      "0s - loss: 160.7353 - r2_keras: -5.9144e-02\n",
      "Epoch 174/300\n",
      "0s - loss: 160.7303 - r2_keras: -6.0747e-02\n",
      "Epoch 175/300\n",
      "0s - loss: 160.7811 - r2_keras: -7.0609e-02\n",
      "Epoch 176/300\n",
      "0s - loss: 160.7341 - r2_keras: -5.4257e-02\n",
      "Epoch 177/300\n",
      "0s - loss: 160.7324 - r2_keras: -6.0883e-02\n",
      "Epoch 178/300\n",
      "0s - loss: 160.7445 - r2_keras: -6.0193e-02\n",
      "Epoch 179/300\n",
      "0s - loss: 160.7367 - r2_keras: -5.6481e-02\n",
      "Epoch 180/300\n",
      "0s - loss: 160.7404 - r2_keras: -5.7945e-02\n",
      "Epoch 181/300\n",
      "0s - loss: 160.7633 - r2_keras: -6.1727e-02\n",
      "Epoch 182/300\n",
      "0s - loss: 160.7339 - r2_keras: -5.5968e-02\n",
      "Epoch 183/300\n",
      "0s - loss: 160.7445 - r2_keras: -6.6030e-02\n",
      "Epoch 184/300\n",
      "0s - loss: 160.7466 - r2_keras: -6.2589e-02\n",
      "Epoch 185/300\n",
      "0s - loss: 160.7345 - r2_keras: -5.3350e-02\n",
      "Epoch 186/300\n",
      "0s - loss: 160.7627 - r2_keras: -5.9240e-02\n",
      "Epoch 187/300\n",
      "0s - loss: 160.7443 - r2_keras: -5.8926e-02\n",
      "Epoch 188/300\n",
      "0s - loss: 160.7402 - r2_keras: -5.7978e-02\n",
      "Epoch 189/300\n",
      "0s - loss: 160.7278 - r2_keras: -6.3555e-02\n",
      "Epoch 190/300\n",
      "0s - loss: 160.7296 - r2_keras: -6.7028e-02\n",
      "Epoch 191/300\n",
      "0s - loss: 160.7270 - r2_keras: -6.4310e-02\n",
      "Epoch 192/300\n",
      "0s - loss: 160.7260 - r2_keras: -4.6268e-02\n",
      "Epoch 193/300\n",
      "0s - loss: 160.7325 - r2_keras: -6.4792e-02\n",
      "Epoch 194/300\n",
      "0s - loss: 160.7362 - r2_keras: -6.8786e-02\n",
      "Epoch 195/300\n",
      "0s - loss: 160.7368 - r2_keras: -6.2683e-02\n",
      "Epoch 196/300\n",
      "0s - loss: 160.7380 - r2_keras: -6.1169e-02\n",
      "Epoch 197/300\n",
      "0s - loss: 160.7297 - r2_keras: -4.9846e-02\n",
      "Epoch 198/300\n",
      "0s - loss: 160.7355 - r2_keras: -5.8925e-02\n",
      "Epoch 199/300\n",
      "0s - loss: 160.7362 - r2_keras: -4.9321e-02\n",
      "Epoch 200/300\n",
      "0s - loss: 160.7206 - r2_keras: -5.2916e-02\n",
      "Epoch 201/300\n",
      "0s - loss: 160.7365 - r2_keras: -6.3707e-02\n",
      "Epoch 202/300\n",
      "0s - loss: 160.7365 - r2_keras: -6.4498e-02\n",
      "Epoch 203/300\n",
      "0s - loss: 160.7393 - r2_keras: -6.6049e-02\n",
      "Epoch 204/300\n",
      "0s - loss: 160.7369 - r2_keras: -6.5438e-02\n",
      "Epoch 205/300\n",
      "0s - loss: 160.7361 - r2_keras: -5.8019e-02\n",
      "Epoch 206/300\n",
      "0s - loss: 160.7358 - r2_keras: -6.6635e-02\n",
      "Epoch 207/300\n",
      "0s - loss: 160.7785 - r2_keras: -6.3425e-02\n",
      "Epoch 208/300\n",
      "0s - loss: 160.7364 - r2_keras: -5.8603e-02\n",
      "Epoch 209/300\n",
      "0s - loss: 160.7344 - r2_keras: -5.7315e-02\n",
      "Epoch 210/300\n",
      "0s - loss: 160.7396 - r2_keras: -5.5710e-02\n",
      "Epoch 211/300\n",
      "0s - loss: 160.7557 - r2_keras: -8.3549e-02\n",
      "Epoch 212/300\n",
      "0s - loss: 160.7392 - r2_keras: -6.7352e-02\n",
      "Epoch 213/300\n",
      "0s - loss: 160.7363 - r2_keras: -5.1530e-02\n",
      "Epoch 214/300\n",
      "0s - loss: 160.7343 - r2_keras: -5.3749e-02\n",
      "Epoch 215/300\n",
      "0s - loss: 160.7357 - r2_keras: -6.0112e-02\n",
      "Epoch 216/300\n",
      "0s - loss: 160.7510 - r2_keras: -6.1897e-02\n",
      "Epoch 217/300\n",
      "0s - loss: 160.7409 - r2_keras: -5.8553e-02\n",
      "Epoch 218/300\n",
      "0s - loss: 160.7334 - r2_keras: -5.8326e-02\n",
      "Epoch 219/300\n",
      "0s - loss: 160.7410 - r2_keras: -6.2547e-02\n",
      "Epoch 220/300\n",
      "0s - loss: 160.7433 - r2_keras: -5.5448e-02\n",
      "Epoch 221/300\n",
      "0s - loss: 160.7302 - r2_keras: -6.3509e-02\n",
      "Epoch 222/300\n",
      "0s - loss: 160.7409 - r2_keras: -6.2043e-02\n",
      "Epoch 223/300\n",
      "0s - loss: 160.7265 - r2_keras: -4.9921e-02\n",
      "Epoch 224/300\n",
      "0s - loss: 160.7352 - r2_keras: -5.6510e-02\n",
      "Epoch 225/300\n",
      "0s - loss: 160.7418 - r2_keras: -6.3562e-02\n",
      "Epoch 226/300\n",
      "0s - loss: 160.7349 - r2_keras: -5.8698e-02\n",
      "Epoch 227/300\n",
      "0s - loss: 160.7404 - r2_keras: -7.9235e-02\n",
      "Epoch 228/300\n",
      "0s - loss: 160.7391 - r2_keras: -7.1371e-02\n",
      "Epoch 229/300\n",
      "0s - loss: 160.7367 - r2_keras: -4.2902e-02\n",
      "Epoch 230/300\n",
      "0s - loss: 160.7377 - r2_keras: -6.3220e-02\n",
      "Epoch 231/300\n",
      "0s - loss: 160.7395 - r2_keras: -5.1243e-02\n",
      "Epoch 232/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s - loss: 160.7389 - r2_keras: -7.3174e-02\n",
      "Epoch 233/300\n",
      "0s - loss: 160.7323 - r2_keras: -5.4846e-02\n",
      "Epoch 234/300\n",
      "0s - loss: 160.7365 - r2_keras: -6.5165e-02\n",
      "Epoch 235/300\n",
      "0s - loss: 160.7371 - r2_keras: -7.0182e-02\n",
      "Epoch 236/300\n",
      "0s - loss: 160.7396 - r2_keras: -6.0438e-02\n",
      "Epoch 237/300\n",
      "0s - loss: 160.7342 - r2_keras: -5.9869e-02\n",
      "Epoch 238/300\n",
      "0s - loss: 160.7442 - r2_keras: -6.1231e-02\n",
      "Epoch 239/300\n",
      "0s - loss: 160.7362 - r2_keras: -5.0825e-02\n",
      "Epoch 240/300\n",
      "0s - loss: 160.7613 - r2_keras: -6.2342e-02\n",
      "Epoch 241/300\n",
      "0s - loss: 160.7499 - r2_keras: -6.7165e-02\n",
      "Epoch 242/300\n",
      "0s - loss: 160.7245 - r2_keras: -5.3012e-02\n",
      "Epoch 243/300\n",
      "0s - loss: 160.7446 - r2_keras: -6.3497e-02\n",
      "Epoch 244/300\n",
      "0s - loss: 160.7511 - r2_keras: -5.9595e-02\n",
      "Epoch 245/300\n",
      "0s - loss: 160.7371 - r2_keras: -5.2636e-02\n",
      "Epoch 246/300\n",
      "0s - loss: 160.7342 - r2_keras: -6.0090e-02\n",
      "Epoch 247/300\n",
      "0s - loss: 160.7238 - r2_keras: -5.4447e-02\n",
      "Epoch 248/300\n",
      "0s - loss: 160.7570 - r2_keras: -6.7809e-02\n",
      "Epoch 249/300\n",
      "0s - loss: 160.7338 - r2_keras: -7.3117e-02\n",
      "Epoch 250/300\n",
      "0s - loss: 160.7547 - r2_keras: -5.9262e-02\n",
      "Epoch 251/300\n",
      "0s - loss: 160.7359 - r2_keras: -5.4578e-02\n",
      "Epoch 252/300\n",
      "0s - loss: 160.7366 - r2_keras: -5.2356e-02\n",
      "Epoch 253/300\n",
      "0s - loss: 160.7213 - r2_keras: -5.8864e-02\n",
      "Epoch 254/300\n",
      "0s - loss: 160.7586 - r2_keras: -5.4604e-02\n",
      "Epoch 255/300\n",
      "0s - loss: 160.7363 - r2_keras: -7.1634e-02\n",
      "Epoch 256/300\n",
      "0s - loss: 160.7568 - r2_keras: -7.4550e-02\n",
      "Epoch 257/300\n",
      "0s - loss: 160.7415 - r2_keras: -5.9337e-02\n",
      "Epoch 258/300\n",
      "0s - loss: 160.7378 - r2_keras: -5.5810e-02\n",
      "Epoch 259/300\n",
      "0s - loss: 160.7375 - r2_keras: -7.0582e-02\n",
      "Epoch 260/300\n",
      "0s - loss: 160.7443 - r2_keras: -5.3594e-02\n",
      "Epoch 261/300\n",
      "0s - loss: 160.7359 - r2_keras: -5.0815e-02\n",
      "Epoch 262/300\n",
      "0s - loss: 160.7510 - r2_keras: -5.6725e-02\n",
      "Epoch 263/300\n",
      "0s - loss: 160.7389 - r2_keras: -6.3310e-02\n",
      "Epoch 264/300\n",
      "0s - loss: 160.7316 - r2_keras: -6.3435e-02\n",
      "Epoch 265/300\n",
      "0s - loss: 160.7353 - r2_keras: -4.7005e-02\n",
      "Epoch 266/300\n",
      "0s - loss: 160.7683 - r2_keras: -5.9426e-02\n",
      "Epoch 267/300\n",
      "0s - loss: 160.7339 - r2_keras: -5.9442e-02\n",
      "Epoch 268/300\n",
      "0s - loss: 160.7372 - r2_keras: -6.5945e-02\n",
      "Epoch 269/300\n",
      "0s - loss: 160.7432 - r2_keras: -5.2727e-02\n",
      "Epoch 270/300\n",
      "0s - loss: 160.7494 - r2_keras: -5.9340e-02\n",
      "Epoch 271/300\n",
      "0s - loss: 160.7300 - r2_keras: -6.1163e-02\n",
      "Epoch 272/300\n",
      "0s - loss: 160.7364 - r2_keras: -7.2270e-02\n",
      "Epoch 273/300\n",
      "0s - loss: 160.7347 - r2_keras: -7.5895e-02\n",
      "Epoch 274/300\n",
      "0s - loss: 160.7292 - r2_keras: -5.3250e-02\n",
      "Epoch 275/300\n",
      "0s - loss: 160.7379 - r2_keras: -5.6447e-02\n",
      "Epoch 276/300\n",
      "0s - loss: 160.7366 - r2_keras: -5.1918e-02\n",
      "Epoch 277/300\n",
      "0s - loss: 160.7437 - r2_keras: -6.1866e-02\n",
      "Epoch 278/300\n",
      "0s - loss: 160.7368 - r2_keras: -4.9263e-02\n",
      "Epoch 279/300\n",
      "0s - loss: 160.7385 - r2_keras: -6.8356e-02\n",
      "Epoch 280/300\n",
      "0s - loss: 160.7285 - r2_keras: -5.3070e-02\n",
      "Epoch 281/300\n",
      "0s - loss: 160.7352 - r2_keras: -6.2429e-02\n",
      "Epoch 282/300\n",
      "0s - loss: 160.7460 - r2_keras: -5.2428e-02\n",
      "Epoch 283/300\n",
      "0s - loss: 160.7510 - r2_keras: -6.0708e-02\n",
      "Epoch 284/300\n",
      "0s - loss: 160.7354 - r2_keras: -6.0526e-02\n",
      "Epoch 285/300\n",
      "0s - loss: 160.7453 - r2_keras: -6.0533e-02\n",
      "Epoch 286/300\n",
      "0s - loss: 160.7471 - r2_keras: -7.5060e-02\n",
      "Epoch 287/300\n",
      "0s - loss: 160.7320 - r2_keras: -6.5117e-02\n",
      "Epoch 288/300\n",
      "0s - loss: 160.7232 - r2_keras: -5.6752e-02\n",
      "Epoch 289/300\n",
      "0s - loss: 160.7362 - r2_keras: -5.6224e-02\n",
      "Epoch 290/300\n",
      "0s - loss: 160.7414 - r2_keras: -5.0561e-02\n",
      "Epoch 291/300\n",
      "0s - loss: 160.7373 - r2_keras: -6.4539e-02\n",
      "Epoch 292/300\n",
      "0s - loss: 160.7338 - r2_keras: -6.0897e-02\n",
      "Epoch 293/300\n",
      "0s - loss: 160.7403 - r2_keras: -6.3191e-02\n",
      "Epoch 294/300\n",
      "0s - loss: 160.7400 - r2_keras: -6.8349e-02\n",
      "Epoch 295/300\n",
      "0s - loss: 160.7487 - r2_keras: -5.8016e-02\n",
      "Epoch 296/300\n",
      "0s - loss: 160.7490 - r2_keras: -5.8130e-02\n",
      "Epoch 297/300\n",
      "0s - loss: 160.7393 - r2_keras: -5.7694e-02\n",
      "Epoch 298/300\n",
      "0s - loss: 160.7385 - r2_keras: -5.0742e-02\n",
      "Epoch 299/300\n",
      "0s - loss: 160.7370 - r2_keras: -5.9047e-02\n",
      "Epoch 300/300\n",
      "0s - loss: 160.7386 - r2_keras: -7.0501e-02\n",
      "  20/1053 [..............................] - ETA: 0s KerasRegressor\n",
      "r2 train =  -5.20003607982e-05\n",
      "r2 eval =  -0.000475306169791\n",
      "====================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_pd, eval_pd, models = eval_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.562194842033\n",
      "0.586563854392\n"
     ]
    }
   ],
   "source": [
    "print(r2_score(train_y, train_pd.median(axis=1)))\n",
    "print(r2_score(eval_y, eval_pd.median(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.582874232858\n",
      "0.596360139532\n"
     ]
    }
   ],
   "source": [
    "print(r2_score(train_y, train_pd[['lr', 'sgd', 'xgb', 'gbr', 'dl', 'thelisen', 'ransac']].median(axis=1)))\n",
    "print(r2_score(eval_y, eval_pd[['lr', 'sgd', 'xgb', 'gbr', 'dl', 'thelisen', 'ransac']].median(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False),\n",
       " SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
       "        fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
       "        loss='squared_loss', n_iter=5, penalty='l2', power_t=0.25,\n",
       "        random_state=None, shuffle=True, verbose=0, warm_start=False),\n",
       " XGBRegressor(base_score=100.66931812782121, booster='gbtree',\n",
       "        colsample_bylevel=1, colsample_bytree=0.7, eta=0.005, gamma=0,\n",
       "        learning_rate=0.1, max_delta_step=0, max_depth=4,\n",
       "        min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "        nthread=1, num_parallel_tree=1, objective='reg:linear',\n",
       "        random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "        seed=0, silent=True, subsample=0.9),\n",
       " GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "              max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False),\n",
       " <keras.wrappers.scikit_learn.KerasRegressor at 0x1f5024bc400>,\n",
       " TheilSenRegressor(copy_X=True, fit_intercept=True, max_iter=300,\n",
       "          max_subpopulation=10000, n_jobs=1, n_subsamples=None,\n",
       "          random_state=42, tol=0.001, verbose=False),\n",
       " RANSACRegressor(base_estimator=None, is_data_valid=None, is_model_valid=None,\n",
       "         loss='absolute_loss', max_trials=100, min_samples=None,\n",
       "         random_state=42, residual_metric=None, residual_threshold=None,\n",
       "         stop_n_inliers=inf, stop_probability=0.99, stop_score=inf),\n",
       " HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,\n",
       "         tol=1e-05, warm_start=False)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4040/4209 [===========================>..] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "for model in models:\n",
    "    preds.append(model.predict(test_feats_encode))\n",
    "    \n",
    "dt = pd.DataFrame(data=np.array(preds).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = dt.median(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'id': test['ID'].astype(np.int32)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output['y'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output.to_csv('results/xgboost/ensemble[%s][%s].csv' % ('ensemble','qweqweqwe123'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
